{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS-GA2059 - Statistics and Data Science for Physicists\n",
    "# Student: Gehan Ranepura\n",
    "## Problem Set #4 - Exercise 8 \n",
    "Hogg et al. (2010). Data analysis recipes: Fitting a model to data.\n",
    "https://doi.org/10.48550/arXiv.1008.4686\n",
    "\n",
    "Compute the standard uncertainty $σ_m^2$ obtained for the slope of the line found by the standard fit you did in Exercise 2. \n",
    "Now make jackknife (20 trials) and bootstrap estimates for the uncertainty $σ_m^2$. \n",
    "How do the uncertainties compare and which seems most reasonable, given the data and uncertainties on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import IPython\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import weighted_linear_least_square_fit as llsq\n",
    "\n",
    "from numpy.linalg import inv\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from pylab import cm\n",
    "\n",
    "''' Set up Plot Style ''' \n",
    "\n",
    "# plt.style.use(['science','nature'])\n",
    "plt.style.use('classic')\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.which'] = 'both'\n",
    "mpl.rcParams['xtick.minor.visible'] = True\n",
    "\n",
    "## use (4,3) for 2 column plots, (8,6) for single plots.\n",
    "fgsz_1 = (8,6)\n",
    "fgsz_2 = (4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201. 592.  61.]\n",
      " [244. 401.  25.]\n",
      " [ 47. 583.  38.]\n",
      " [287. 402.  15.]\n",
      " [203. 495.  21.]\n",
      " [ 58. 173.  15.]\n",
      " [210. 479.  27.]\n",
      " [202. 504.  14.]\n",
      " [198. 510.  30.]\n",
      " [158. 416.  16.]\n",
      " [165. 393.  14.]\n",
      " [201. 442.  25.]\n",
      " [157. 317.  52.]\n",
      " [131. 311.  16.]\n",
      " [166. 400.  34.]\n",
      " [160. 337.  31.]\n",
      " [186. 423.  42.]\n",
      " [125. 334.  26.]\n",
      " [218. 533.  16.]\n",
      " [146. 344.  22.]]\n"
     ]
    }
   ],
   "source": [
    "data_file = np.loadtxt(\"data.txt\", dtype=float)\n",
    "data = data_file[:,0:3]\n",
    "print(data)\n",
    "\n",
    "#  Read data file at path 'file_path'. Return a np array data = array(...).\n",
    "#  Read data to ignore the first 5 data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JackKnife Method:\n",
    "\n",
    "In jackknife, you make your measurement $N$ times, but each time leaving out data point $i$.\n",
    "\n",
    "For each trial, use standard weighted linear least-square fit but leaving out data point $i$, to obtain $m_i, b_i$: \n",
    "$$ \\sigma_m^2=\\frac{N-1}{N} \\sum_{i=1}^N \\left[m_i -m\\right]^2 $$\n",
    "$$ \\sigma_b^2=\\frac{N-1}{N} \\sum_{i=1}^N \\left[b_i -b\\right]^2 $$\n",
    "\n",
    "where, $m, b$ is the average over all $N$ trials.\n",
    "$$ m = \\frac{1}{N} \\sum_{i=1}^N m_i $$ \n",
    "$$ b = \\frac{1}{N} \\sum_{i=1}^N b_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0ced16126b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# Number of trials = number of data points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdpID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Data point ID, correspond each data point with a list ID number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create data series in pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm_jkls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "N = len(data)            # Number of trials = number of data points\n",
    "dpID = np.arange(0,N,1)  # Data point ID, correspond each data point with a list ID number\n",
    "\n",
    "# Create data series in pandas\n",
    "m_jkls = pd.Series([],dtype=object)\n",
    "b_jkls = pd.Series([],dtype=object)\n",
    "m_sig_jkls = pd.Series([],dtype=object)\n",
    "b_sig_jkls = pd.Series([],dtype=object)\n",
    "\n",
    "# Perform weighted linear least-square fit over a loop, excluding the data point i each time\n",
    "for i in range(N):\n",
    "    dpID_i = np.delete(dpID, i)\n",
    "    data_i = data[dpID_i]\n",
    "    m_jkls[i], b_jkls[i], m_sig_jkls[i], b_sig_jkls[i] = llsq.weighted_linear_least_square_fit(data_i)\n",
    "\n",
    "# Find m,b which is merely the average of all trials (N)\n",
    "m_jk = np.mean(m_jkls)\n",
    "b_jk = np.mean(b_jkls)\n",
    "\n",
    "# Find uncertainty for m,b\n",
    "m_sig_jk = np.std(m_jkls)*np.sqrt(N-1)  # Uncertainity of m_jk is merely the standard deviation of m_jk * sqrt(N-1)\n",
    "b_sig_jk = np.std(b_jkls)*np.sqrt(N-1)  # Uncertainity of b_jk is merely the standard deviation of b_jk * sqrt(N-1)\n",
    "\n",
    "print(\"m_res_jk =  %s \\pm %s\"%(round(m_jk,2),round(m_sig_jk,2)) )\n",
    "print(\"b_res_jk =  %s \\pm %s\"%(round(b_jk,2),round(b_sig_jk,2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Method:\n",
    "In bootstrap, you make your measurement $M$ times but each time randomly choose $N$ points (with replacement) from the dataset. \n",
    "\n",
    "For each trial, use standard weighted linear least-square fit for each selection of N points to obtain $m_j,b_j$:\n",
    "$$\\sigma_m^2=\\frac{1}{M} \\sum_{j=1}^M\\left[m_j-m\\right]^2$$\n",
    "$$\\sigma_b^2=\\frac{1}{M} \\sum_{j=1}^M\\left[b_j-b\\right]^2$$\n",
    "\n",
    "where, $m, b$ is the average over all $M$ trials.\n",
    "$$ m = \\frac{1}{M} \\sum_{j=1}^M m_j $$\n",
    "$$ b = \\frac{1}{M} \\sum_{j=1}^M b_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_res_boot =  1.17 \\pm 0.66\n",
      "b_res_boot =  195.76 \\pm 114.45\n"
     ]
    }
   ],
   "source": [
    "N = len(data)           # Number of data points\n",
    "dpID = np.arange(0,N,1) # Data point ID, correspond each data point with a list ID number\n",
    "M = N+2                 # Number of trials, if M is comparable to N, there probably isn't much else you can learn.\n",
    "\n",
    "# Create data series in pandas\n",
    "m_bootls = pd.Series([],dtype=object)\n",
    "b_bootls = pd.Series([],dtype=object)\n",
    "m_sig_bootls = pd.Series([],dtype=object)\n",
    "b_sig_bootls = pd.Series([],dtype=object)\n",
    "\n",
    "# Perform weighted linear least-square fit over a loop, with randomized N data points from dataset\n",
    "rng = np.random.default_rng()          # Random number generator\n",
    "for j in range(M):\n",
    "    dpID_j = rng.integers(0,N, size=N) # Create list of randomized integers from 0 to N\n",
    "    data_j = data[dpID_j]              # Choose data points that correspond to the list of integers from 0 to N\n",
    "    m_bootls[j], b_bootls[j], m_sig_bootls[j], b_sig_bootls[j] = llsq.weighted_linear_least_square_fit(data_j)\n",
    "\n",
    "# Find m,b which is merely the average of all trials (M)    \n",
    "m_boot = np.mean(m_bootls)    \n",
    "b_boot = np.mean(b_bootls)\n",
    "\n",
    "# Find uncertainty for m,b\n",
    "m_sig_boot = np.std(m_bootls)          # Uncertainity of m_boot is merely the standard deviation of m_boot\n",
    "b_sig_boot = np.std(b_bootls)          # Uncertainity of b_boot is merely the standard deviation of b_boot\n",
    "\n",
    "print( \"m_res_boot =  %s \\pm %s\"%(round(m_boot,2),round(m_sig_boot,2)) )\n",
    "print( \"b_res_boot =  %s \\pm %s\"%(round(b_boot,2),round(b_sig_boot,2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "How do the uncertainties compare and which seems most reasonable, given the data and uncertainties on the data?\n",
    "\n",
    "~ Both the JackKnife and Boostrap methods seem to give decent estimates for the data. Jackknife always gives the same result of the measurement of m,b and their asscoiated uncertainites. However it seems that due to random nature of data picking in the Bootstrap method, the measurements we get are always changing. Therefore, there is a higher probability of getting innaccurate measurements with the bootstrap method when a single data point is chosen too mnay times, encompassing a smaller pool of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
